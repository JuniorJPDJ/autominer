#!/bin/env perl

# Copyright (c) 2017 Todd Freed <todd.freed@gmail.com>
# 
# This file is part of autominer.
# 
# autominer is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# autominer is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License

use strict;
use warnings;

use File::Basename;
use Cwd;
our $repodir;
BEGIN { $repodir = dirname(Cwd::realpath("$0/..")) }
use lib "$repodir/lib";
use util;
use release;
override_warn_and_die();

use Time::Piece;
use JSON::XS;
use File::Find;
use config;
use market::nicehash;
use profitability;

our $verbose = 0;
our %opts = (
    'retention'     => 2 * 60 * 24 # 24 hours
  , 'datadir'       => $ENV{HOME} . "/.autominer/data"
  , 'profile'       => 'default'
);
my %optargs = (
    'help|h'        => \$opts{help}
  , 'version|V'     => \$opts{version}
  , 'verbose|v'     => \$opts{verbose}

  , 'profile=s'     => \$opts{profile}
  , 'period=i'      => \$opts{period}
  , 'retention=i'   => \$opts{retention}
  , 'data-dir=s'    => \$opts{"datadir"}
);
configure(\%optargs, \%opts);

if($opts{help})
{
  print <<HELP;
autominer - an autoswitching miner for linux, version $release::number

 >> BTC donations : 184AtMD3AihYke2bKQD9AXh4Dgzvtr7jhA (hossbeast)

usage: nicehash-aggregator [options]

 --help                 print this help text
 --version              print the version number, exit
 --verbose              print commands as they are run

required
 --data-dir <path>

optional
 --retention <number>   number of results to retain

For more information visit https://github.com/hossbeast/autominer
HELP
  exit 0
}
if($opts{version})
{
  print "autominer-$release::number\n";
  exit 0;
}

my $ratesdir = "$opts{datadir}/rates/nicehash";
my $spooldir = "$opts{datadir}/rates/nicehash/spool";
my $samplesdir = "$opts{datadir}/rates/nicehash/samples";
my $min_file;
my $max_file = 0;
my %slices;         # {m1} => [ { algo => price, algo => price } ] 
my %sums;           # {m1}{algo} => sum
my $num = 0;
my $report = 0;
my $writer = JSON::XS->new->pretty(1);

mkdir($ratesdir);
mkdir($spooldir);
mkdir($samplesdir);

my $stats_global_current = nicehash::stats_global_current();
for my $algo (keys %$stats_global_current)
{
  for my $win (qw|s30 m1 m5 m10 h1 h3|)
  {
    $slices{$win}[0]{$algo} = 0;
    $sums{$win}{$algo} = 0;
  }
}

sub process
{
  my ($dir, $num_file) = @_;

  $min_file = $num_file unless defined $min_file;
  $max_file = $num_file;

  open(my $fh, sprintf("<$dir/%05u", $num_file)) or die $!;
  my $text = do { local $/ = undef ; <$fh> };
  close $fh;

  if(($max_file - $min_file) > $opts{retention})
  {
    unlink sprintf("$dir/%05u", $min_file);
    $min_file++;
  }

  my $current = decode_json($text);

  my $cycle = sub {
    my ($name, $slice, $sum, $period, $capacity) = @_;

    if($num && (($num % $period) == 0))
    {
      # shift off the oldest slice
      if(($#$slice + 1) == $capacity)
      {
        while(my($algo, $price) = each %{$$slice[-1]})
        {
          $$sum{$algo} -= $price;
        }

        pop @$slice;
      }

      # accumulate into the newest slice
      unshift @$slice, { };
    }
  };

  $cycle->("s30", $slices{s30}, $sums{s30}, 1                 , 2);   # 2x 30-second slices
  $cycle->("m1",  $slices{m1},  $sums{m1},  1 * 2             , 5);   # 5x  1-minute slices
  $cycle->("m5",  $slices{m5},  $sums{m5},  1 * 2 * 5         , 2);   # 2x  5-minute slices
  $cycle->("m10", $slices{m10}, $sums{m10}, 1 * 2 * 5 * 2     , 6);   # 6x 10-minute slices
  $cycle->("h1",  $slices{h1},  $sums{h1},  1 * 2 * 5 * 2 * 6 , 3);   # 3x  1-hour slices

  my $cascade = sub {
    my ($name, $slice, $sum, $next, $period) = @_;

    if(($num % $period) == 0)
    {
      while(my($algo, $price) = each %{$$slice[0]})
      {
        $$sum{$algo} += $price;
      }
    }

    # cascade
    for my $algo (keys %{$$slice[0]})
    {
      $$next[0]{$algo} = $$sum{$algo} / ($#$slice + 1);
    }
  };

  # apply the new prices to the current slice
  $slices{s30}[0] = $current;

  $cascade->("m1" , $slices{s30}, $sums{s30}, $slices{m1} , 1                );
  $cascade->("m5" , $slices{m1} , $sums{m1} , $slices{m5} , 1 * 2            );
  $cascade->("m10", $slices{m5} , $sums{m5} , $slices{m10}, 1 * 2 * 5        );
  $cascade->("h1" , $slices{m10}, $sums{m10}, $slices{h1} , 1 * 2 * 5 * 2    );
  $cascade->("h3" , $slices{h1} , $sums{h1} , $slices{h3} , 1 * 2 * 5 * 2 * 6);

  $num++;

  return unless $report;

  if(($num % 1) == 0)
  {
    printf("%s : %d samples\n", scalar localtime, $max_file - $min_file);
  }

  open($fh, ">$spooldir/s30") or die $!;
  print $fh ($writer->encode($slices{s30}[0]));
  close $fh;
  rename("$spooldir/s30", "$ratesdir/s30") or die $!;

  open($fh, ">$spooldir/m1") or die $!;
  print $fh ($writer->encode($slices{m1}[0]));
  close $fh;
  rename("$spooldir/m1", "$ratesdir/m1") or die $!;

  open($fh, ">$spooldir/m5") or die $!;
  print $fh ($writer->encode($slices{m5}[0]));
  close $fh;
  rename("$spooldir/m5", "$ratesdir/m5") or die $!;

  open($fh, ">$spooldir/m10") or die $!;
  print $fh ($writer->encode($slices{m10}[0]));
  close $fh;
  rename("$spooldir/m10", "$ratesdir/m10") or die $!;

  open($fh, ">$spooldir/h1") or die $!;
  print $fh ($writer->encode($slices{h1}[0]));
  close $fh;
  rename("$spooldir/h1", "$ratesdir/h1") or die $!;

  open($fh, ">$spooldir/h3") or die $!;
  print $fh ($writer->encode($slices{h3}[0]));
  close $fh;
  rename("$spooldir/h3", "$ratesdir/h3") or die $!;
}

my $wanted = sub {
  return if $_ eq "." or $_ eq "..";

  process($samplesdir, int($_));
};
my $preprocess = sub {
  sort { int($a) <=> int($b) }  # increasing order
  grep { /^[0-9]+$/ } @_
};

chdir($samplesdir) or die "chdir($samplesdir) : $!";
finddepth({ wanted => $wanted, preprocess => $preprocess }, ".");

$report = 1;

for(my $i = 0; 1; $i++)
{
  my $T = $^T;

  $max_file++;
  open(my $fh, sprintf(">$samplesdir/%05u", $max_file)) or die $!;
  print $fh ($writer->encode($stats_global_current));
  close $fh;

  process($samplesdir, $max_file);

  sleep(30 - ($^T - $T));

  my $stats_next = nicehash::stats_global_current();
  $stats_global_current = $stats_next if $stats_next;
}
